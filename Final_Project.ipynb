{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "14Gr8rvKTR_0_4IjGCvM_ddS7bYe1zR4F",
      "authorship_tag": "ABX9TyM9heWmCvwdfAIO7oK9htpG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jonathan-code-hub/MAT-422-Math-Methods-in-Data-Science/blob/main/Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment Analysis"
      ],
      "metadata": {
        "id": "28ybA85v210h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This downloads the data from Kaggle"
      ],
      "metadata": {
        "id": "puEbErM8dE12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download Latest Version of Movie Review Data #\n",
        "path = kagglehub.dataset_download(\"vishakhdapat/imdb-movie-reviews\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Download Latest Version Financial Sentiment Analysis Data #\n",
        "path = kagglehub.dataset_download(\"sbhatti/financial-sentiment-analysis\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Download Latest Version Twitter Sentiment Analysis Data #\n",
        "path = kagglehub.dataset_download(\"jp797498e/twitter-entity-sentiment-analysis\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4B4xIdjfdFFA",
        "outputId": "adf1cfe6-7e05-4f27-b89f-2f2c41e3c625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/vishakhdapat/imdb-movie-reviews?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25.7M/25.7M [00:00<00:00, 127MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/vishakhdapat/imdb-movie-reviews/versions/1\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/sbhatti/financial-sentiment-analysis/versions/4\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/jp797498e/twitter-entity-sentiment-analysis/versions/2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code downloads the VADER lexicon."
      ],
      "metadata": {
        "id": "mXxVODys6CMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download VADER lexicon (only needs to be done once) #\n",
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "id": "4UwOh-zU55q4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bef8608e-cb81-4a0a-b373-2e954536d5d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLTK Most Basic Implementation"
      ],
      "metadata": {
        "id": "Bha1IVBv22Rd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "\n",
        "#  This function classifies sentiment based on compound score #\n",
        "def classify_sentiment(text):\n",
        "    score = sia.polarity_scores(text)['compound']\n",
        "    if score > 0.05:\n",
        "        return \"Positive\"\n",
        "    elif score < -0.05:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "# Initialize SentimentIntensityAnalyzer #\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Example texts #\n",
        "\n",
        "text_1 = \"I love this thing! Awesome! Super great!\"\n",
        "\n",
        "text_2 = \"This is so dumb and stupid and bad! I hate it!\"\n",
        "\n",
        "# Get sentiment scores #\n",
        "\n",
        "scores_1 = sia.polarity_scores(text_1)\n",
        "\n",
        "scores_2 = sia.polarity_scores(text_2)\n",
        "\n",
        "# Print the sentiment scores #\n",
        "print(\"Text 1 Scores\")\n",
        "print(scores_1)\n",
        "print(\"Likely Sentiment:\", classify_sentiment(text_1))\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Text 2 Scores\")\n",
        "print(scores_2)\n",
        "print(\"Likely Sentiment:\", classify_sentiment(text_2))\n",
        "\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k25wTs1B23FR",
        "outputId": "2b05c5f3-e66e-492d-f774-fb7cbef32a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 1 Scores\n",
            "{'neg': 0.0, 'neu': 0.104, 'pos': 0.896, 'compound': 0.9594}\n",
            "Likely Sentiment: Positive\n",
            "\n",
            "Text 2 Scores\n",
            "{'neg': 0.723, 'neu': 0.277, 'pos': 0.0, 'compound': -0.9493}\n",
            "Likely Sentiment: Negative\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Textblob Analysis"
      ],
      "metadata": {
        "id": "5MZWafU7AI8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# Sample texts #\n",
        "text_1 = \"I love this thing! Awesome! Super great!\"\n",
        "\n",
        "text_2 = \"This is so dumb and stupid and bad! I hate it!\"\n",
        "\n",
        "# Sentiment analysis #\n",
        "blob_1 = TextBlob(text_1)\n",
        "blob_2 = TextBlob(text_2)\n",
        "\n",
        "# Classification #\n",
        "\n",
        "sentiment_1 = \"Positive\" if blob_1.sentiment.polarity > 0 else \"Negative\" if blob_1.sentiment.polarity < 0 else \"Neutral\"\n",
        "\n",
        "sentiment_2 = \"Positive\" if blob_2.sentiment.polarity > 0 else \"Negative\" if blob_2.sentiment.polarity < 0 else \"Neutral\"\n",
        "\n",
        "# Print the sentiment scores #\n",
        "print(\"Polarity:\", blob_1.sentiment.polarity)  # Range: -1 to 1 #\n",
        "print(\"Subjectivity:\", blob_1.sentiment.subjectivity)  # Range: 0 to 1 #\n",
        "\n",
        "print(\"Likely Sentiment:\", sentiment_1)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Polarity:\", blob_2.sentiment.polarity)  # Range: -1 to 1 #\n",
        "print(\"Subjectivity:\", blob_2.sentiment.subjectivity)  # Range: 0 to 1 #\n",
        "\n",
        "print(\"Likely Sentiment:\", sentiment_2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koJF8FdHAmP6",
        "outputId": "4c2f6363-7c85-4941-8bba-82d4d288ef58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polarity: 0.7395833333333333\n",
            "Subjectivity: 0.7541666666666667\n",
            "Likely Sentiment: Positive\n",
            "\n",
            "Polarity: -0.7625\n",
            "Subjectivity: 0.7666666666666666\n",
            "Likely Sentiment: Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine Learning Model (Using Sci-Kit)"
      ],
      "metadata": {
        "id": "Hs_hMXEPAmeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Sample dataset #\n",
        "data = [\n",
        "    (\"I love this product!\", \"positive\"),\n",
        "    (\"This is the worst thing I've bought.\", \"negative\"),\n",
        "    (\"Not bad, could be better.\", \"neutral\"),\n",
        "    (\"Absolutely fantastic!\", \"positive\"),\n",
        "    (\"Terrible experience.\", \"negative\"),\n",
        "    (\"It was so-so.\", \"neutral\"),\n",
        "    (\"I hated this it's horrible, so bad\", \"negative\")\n",
        "]\n",
        "texts, labels = zip(*data)\n",
        "\n",
        "# Vectorize text #\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(texts)\n",
        "\n",
        "# Split data #\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train classifier #\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate #\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Test on new text #\n",
        "new_text = [\"I hate the service.\"]\n",
        "new_vector = vectorizer.transform(new_text)\n",
        "print(\"Sentiment:\", classifier.predict(new_vector))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGu4k4yjCtTm",
        "outputId": "dfca390c-5995-4010-b8f8-634f3fbfdc05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.00      0.00      0.00       1.0\n",
            "    positive       0.00      0.00      0.00       1.0\n",
            "\n",
            "    accuracy                           0.00       2.0\n",
            "   macro avg       0.00      0.00      0.00       2.0\n",
            "weighted avg       0.00      0.00      0.00       2.0\n",
            "\n",
            "Sentiment: ['negative']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine Learning Trained On Data Sets"
      ],
      "metadata": {
        "id": "nwlR_iE4ZucQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naiveMovieort MultinomialNB\n",
        "from sklearn.metriMovieclassification_report\n",
        "\n",
        "# Data Reading #\n",
        "\n",
        "data1 = pd.read_csv(\"/root/.cache/kagglehub/datasets/jp797498e/twitter-entity-sentiment-analysis/versions/2/twitter_training.csv\")\n",
        "\n",
        "data2 = pd.read_csv(\"/root/.cache/kagglehub/datasets/sbhatti/financial-sentiment-analysis/versions/4/data.csv\")\n",
        "\n",
        "data3 = pd.read_csv(\"/root/.cache/kagglehub/datasets/vishakhdapat/imdb-movie-reviews/versions/1/IMDB Dataset.csv\")\n",
        "\n",
        "# Data Prep #\n",
        "\n",
        "data1 = data1.iloc[:, [2, 3]]\n",
        "data2 = data2[['Sentence', 'Sentiment']]\n",
        "data3 = data3[['review', 'sentiment']]\n",
        "\n",
        "# This code prints the pre data prep shape #\n",
        "# print(\"Dataset Shape:\", data1.shape)\n",
        "# print(\"Dataset Shape:\", data2.shape)\n",
        "# print(\"Dataset Shape:\", data3.shape)\n",
        "\n",
        "data1.columns = ['text', 'sentiment']\n",
        "\n",
        "data2.columns = ['text', 'sentiment']\n",
        "\n",
        "data3.columns = ['text', 'sentiment']\n",
        "\n",
        "\n",
        "# Convert the 'text' column to lowercase #\n",
        "\n",
        "data1.loc[:, 'text'] = data1['text'].str.lower()\n",
        "\n",
        "data2.loc[:, 'text'] = data1['text'].str.lower()\n",
        "\n",
        "data3.loc[:, 'text'] = data1['text'].str.lower()\n",
        "\n",
        "# Filter out rows where 'sentiment' is 'irrelevant' #\n",
        "\n",
        "data1 = data1[data1['sentiment'] != 'irrelevant']\n",
        "\n",
        "data2 = data2[data2['sentiment'] != 'irrelevant']\n",
        "\n",
        "data3 = data3[data3['sentiment'] != 'irrelevant']\n",
        "\n",
        "# This code is to check the shape after data prep #\n",
        "# print(\"Dataset Shape:\", data1.shape)\n",
        "# print(\"Dataset Shape:\", data2.shape)\n",
        "# print(\"Dataset Shape:\", data3.shape)\n",
        "\n",
        "data1.dropna(inplace=True)\n",
        "\n",
        "data2.dropna(inplace=True)\n",
        "\n",
        "data3.dropna(inplace=True)\n",
        "\n",
        "# If you don't have the runtime and computing power you should just use this #\n",
        "combined_data = data2\n",
        "\n",
        "# Uncomment these if you have proper runtime #\n",
        "# combined_data = pd.concat([data1, data2], ignore_index=True)\n",
        "# combined_data = pd.concat([combined_data, data3], ignore_index=True)\n",
        "\n",
        "print(\"Combined Dataset Shape:\", combined_data.shape)\n",
        "\n",
        "texts = combined_data['text']\n",
        "labels = combined_data['sentiment']\n",
        "\n",
        "# Vectorize text #\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(texts)\n",
        "\n",
        "# Split data #\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train classifier #\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate #\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Test on new text #\n",
        "new_text = [\"Hello world!\"]\n",
        "new_vector = vectorizer.transform(new_text)\n",
        "print(\"Sentiment:\", classifier.predict(new_vector))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RH1c0ivvtUDW",
        "outputId": "47809191-85df-4b61-d7f6-635e8b13a9c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Dataset Shape: (5842, 2)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.00      0.00      0.00       175\n",
            "     neutral       0.53      1.00      0.69       622\n",
            "    positive       0.00      0.00      0.00       372\n",
            "\n",
            "    accuracy                           0.53      1169\n",
            "   macro avg       0.18      0.33      0.23      1169\n",
            "weighted avg       0.28      0.53      0.37      1169\n",
            "\n",
            "Sentiment: ['neutral']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Given values\n",
        "import numpy as np\n",
        "\n",
        "# Constants\n",
        "hbar = 1.055e-34      # Planck constant [J·s]\n",
        "G = 6.67e-11          # Gravitational constant [N·m²/kg²]\n",
        "pc = 3.09e16          # 1 parsec in meters\n",
        "M_solar = 1.99e30     # Solar mass in kg\n",
        "c = 3e8               # Speed of light in m/s\n",
        "eV_J = 1.602e-19      # 1 eV in joules\n",
        "\n",
        "# Galaxy parameters\n",
        "rt_pc = 830           # tidal radius in parsecs\n",
        "Mdwarf_Msun = 2.5e7   # dwarf galaxy mass in solar masses\n",
        "\n",
        "# Convert to SI units\n",
        "rt = rt_pc * pc\n",
        "Mdwarf = Mdwarf_Msun * M_solar\n",
        "\n",
        "# From part a), the result was:\n",
        "# mc^2 ~ (ℏ^3 G Mdwarf) / rt^4\n",
        "# Let's compute that and then convert J to eV\n",
        "\n",
        "numerator = hbar**3 * G * Mdwarf\n",
        "denominator = rt**4\n",
        "\n",
        "mc2_J = numerator / denominator\n",
        "mc2_eV = mc2_J / eV_J\n",
        "\n",
        "mc2_eV\n"
      ],
      "metadata": {
        "id": "PWmlqTNa7LR9",
        "outputId": "4f6e83cc-c88a-47e1-c939-21ff54c9e633",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.621697838624407e-134"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chatgpt Implementation"
      ],
      "metadata": {
        "id": "1Et2vl4pCtqT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This requires an OpenAI API KEY"
      ],
      "metadata": {
        "id": "qa67fI_3Cy0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28\n",
        "\n",
        "import openai\n",
        "\n",
        "# Set your OpenAI API key #\n",
        "openai.api_key = \"API-KEY-HERE\"\n",
        "\n",
        "# Function to analyze sentiment using ChatGPT #\n",
        "def chatgpt_sentiment_analysis(text):\n",
        "    prompt = f\"Classify the sentiment of this text as Positive, Negative, or Neutral: '{text}'\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",  # You can also use \"gpt-4\"\n",
        "        messages=[{\"role\": \"system\", \"content\": \"You are a sentiment analysis assistant.\"},\n",
        "                  {\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=50\n",
        "    )\n",
        "\n",
        "    return response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "# Example Texts #\n",
        "text_1 = \"I love this thing! Awesome! Super great!\"\n",
        "\n",
        "text_2 = \"This is so dumb and stupid and bad! I hate it!\"\n",
        "\n",
        "\n",
        "sentiment_1 = chatgpt_sentiment_analysis(text_1)\n",
        "\n",
        "sentiment_2 = chatgpt_sentiment_analysis(text_2)\n",
        "\n",
        "print(\"Likely Sentiment:\", sentiment_1)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Likely Sentiment:\", sentiment_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "MmMFHdcHAmv4",
        "outputId": "114de09e-27bc-4499-8f56-2afef6463353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.11.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AuthenticationError",
          "evalue": "Incorrect API key provided: API-KEY-HERE. You can find your API key at https://platform.openai.com/account/api-keys.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ddf659033183>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0msentiment_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchatgpt_sentiment_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0msentiment_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchatgpt_sentiment_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-ddf659033183>\u001b[0m in \u001b[0;36mchatgpt_sentiment_analysis\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Classify the sentiment of this text as Positive, Negative, or Neutral: '{text}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     response = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# You can also use \"gpt-4\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         messages=[{\"role\": \"system\", \"content\": \"You are a sentiment analysis assistant.\"},\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    766\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             )\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: Incorrect API key provided: API-KEY-HERE. You can find your API key at https://platform.openai.com/account/api-keys."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing Methods Section:"
      ],
      "metadata": {
        "id": "lHLjnQj138ld"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLTK"
      ],
      "metadata": {
        "id": "MkQgmckF4CtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "\n",
        "# This function classifies sentiment based on compound score #\n",
        "def classify_sentiment(text):\n",
        "    score = sia.polarity_scores(text)['compound']\n",
        "    if score > 0.05:\n",
        "        return \"positive\"\n",
        "    elif score < -0.05:\n",
        "        return \"negative\"\n",
        "    else:\n",
        "        return \"neutral\"\n",
        "\n",
        "# Initialize SentimentIntensityAnalyzer #\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Data Reading #\n",
        "\n",
        "data1 = pd.read_csv(\"/root/.cache/kagglehub/datasets/jp797498e/twitter-entity-sentiment-analysis/versions/2/twitter_training.csv\")\n",
        "data2 = pd.read_csv(\"/root/.cache/kagglehub/datasets/sbhatti/financial-sentiment-analysis/versions/4/data.csv\")\n",
        "data3 = pd.read_csv(\"/root/.cache/kagglehub/datasets/vishakhdapat/imdb-movie-reviews/versions/1/IMDB Dataset.csv\")\n",
        "\n",
        "# Data Prep #\n",
        "\n",
        "data1 = data1.iloc[:, [2, 3]]\n",
        "data2 = data2[['Sentence', 'Sentiment']]\n",
        "data3 = data3[['review', 'sentiment']]\n",
        "\n",
        "data1.columns = ['text', 'sentiment']\n",
        "data2.columns = ['text', 'sentiment']\n",
        "data3.columns = ['text', 'sentiment']\n",
        "\n",
        "# Convert the 'text' column to lowercase #\n",
        "\n",
        "data1.loc[:, 'text'] = data1['text'].str.lower()\n",
        "data2.loc[:, 'text'] = data2['text'].str.lower()\n",
        "data3.loc[:, 'text'] = data3['text'].str.lower()\n",
        "\n",
        "# Filter out rows where 'sentiment' is 'irrelevant' #\n",
        "\n",
        "data1 = data1[data1['sentiment'] != 'irrelevant']\n",
        "data2 = data2[data2['sentiment'] != 'irrelevant']\n",
        "data3 = data3[data3['sentiment'] != 'irrelevant']\n",
        "\n",
        "# Drop missing values #\n",
        "\n",
        "data1.dropna(inplace=True)\n",
        "data2.dropna(inplace=True)\n",
        "data3.dropna(inplace=True)\n",
        "\n",
        "# Evaluate on each dataset #\n",
        "\n",
        "# Function to calculate accuracy for a given dataset\n",
        "def calculate_accuracy(data):\n",
        "    predicted_sentiments = data['text'].apply(classify_sentiment)\n",
        "    accuracy = accuracy_score(data['sentiment'], predicted_sentiments)\n",
        "    return accuracy\n",
        "\n",
        "# Calculate accuracy for each dataset\n",
        "accuracy_data1 = calculate_accuracy(data1)\n",
        "accuracy_data2 = calculate_accuracy(data2)\n",
        "accuracy_data3 = calculate_accuracy(data3)\n",
        "\n",
        "# Print accuracy results\n",
        "print(f\"Accuracy for Data1: {accuracy_data1:.4f}\")\n",
        "print(f\"Accuracy for Data2: {accuracy_data2:.4f}\")\n",
        "print(f\"Accuracy for Data3: {accuracy_data3:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ6FYunN4Cf-",
        "outputId": "a13ca8db-62e0-4492-93ea-ac0eb8db91ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Data1: 0.0000\n",
            "Accuracy for Data2: 0.5077\n",
            "Accuracy for Data3: 0.6928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TextBlob"
      ],
      "metadata": {
        "id": "cuLFVmrp4BMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Data Reading #\n",
        "\n",
        "data1 = pd.read_csv(\"/root/.cache/kagglehub/datasets/jp797498e/twitter-entity-sentiment-analysis/versions/2/twitter_training.csv\")\n",
        "data2 = pd.read_csv(\"/root/.cache/kagglehub/datasets/sbhatti/financial-sentiment-analysis/versions/4/data.csv\")\n",
        "data3 = pd.read_csv(\"/root/.cache/kagglehub/datasets/vishakhdapat/imdb-movie-reviews/versions/1/IMDB Dataset.csv\")\n",
        "\n",
        "# Data Prep #\n",
        "\n",
        "data1 = data1.iloc[:, [2, 3]]\n",
        "data2 = data2[['Sentence', 'Sentiment']]\n",
        "data3 = data3[['review', 'sentiment']]\n",
        "\n",
        "data1.columns = ['text', 'sentiment']\n",
        "data2.columns = ['text', 'sentiment']\n",
        "data3.columns = ['text', 'sentiment']\n",
        "\n",
        "# Convert the 'text' column to lowercase #\n",
        "\n",
        "data1.loc[:, 'text'] = data1['text'].str.lower()\n",
        "data2.loc[:, 'text'] = data2['text'].str.lower()\n",
        "data3.loc[:, 'text'] = data3['text'].str.lower()\n",
        "\n",
        "# Filter out rows where 'sentiment' is 'irrelevant' #\n",
        "\n",
        "data1 = data1[data1['sentiment'] != 'irrelevant']\n",
        "data2 = data2[data2['sentiment'] != 'irrelevant']\n",
        "data3 = data3[data3['sentiment'] != 'irrelevant']\n",
        "\n",
        "# Drop missing values #\n",
        "\n",
        "data1.dropna(inplace=True)\n",
        "data2.dropna(inplace=True)\n",
        "data3.dropna(inplace=True)\n",
        "\n",
        "# Function to classify sentiment using TextBlob #\n",
        "def classify_sentiment(text):\n",
        "    blob = TextBlob(text)\n",
        "    if blob.sentiment.polarity > 0:\n",
        "        return \"positive\"\n",
        "    elif blob.sentiment.polarity < 0:\n",
        "        return \"negative\"\n",
        "    else:\n",
        "        return \"neutral\"\n",
        "\n",
        "# Function to calculate accuracy for a given dataset\n",
        "def calculate_accuracy(data):\n",
        "    predicted_sentiments = data['text'].apply(classify_sentiment)\n",
        "    accuracy = accuracy_score(data['sentiment'], predicted_sentiments)\n",
        "    return accuracy\n",
        "\n",
        "# Calculate accuracy for each dataset\n",
        "accuracy_data1 = calculate_accuracy(data1)\n",
        "accuracy_data2 = calculate_accuracy(data2)\n",
        "accuracy_data3 = calculate_accuracy(data3)\n",
        "\n",
        "# Print accuracy results\n",
        "print(f\"Accuracy for Data1: {accuracy_data1:.4f}\")\n",
        "print(f\"Accuracy for Data2: {accuracy_data2:.4f}\")\n",
        "print(f\"Accuracy for Data3: {accuracy_data3:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFlrh1Wq38WW",
        "outputId": "b84d166c-d751-4b6b-afd8-e8fe888665b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Data1: 0.0000\n",
            "Accuracy for Data2: 0.4581\n",
            "Accuracy for Data3: 0.6885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine Learning"
      ],
      "metadata": {
        "id": "uFETAdZCacEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Data Reading #\n",
        "\n",
        "data1 = pd.read_csv(\"/root/.cache/kagglehub/datasets/jp797498e/twitter-entity-sentiment-analysis/versions/2/twitter_training.csv\")\n",
        "data2 = pd.read_csv(\"/root/.cache/kagglehub/datasets/sbhatti/financial-sentiment-analysis/versions/4/data.csv\")\n",
        "data3 = pd.read_csv(\"/root/.cache/kagglehub/datasets/vishakhdapat/imdb-movie-reviews/versions/1/IMDB Dataset.csv\")\n",
        "\n",
        "# Data Prep #\n",
        "\n",
        "data1 = data1.iloc[:, [2, 3]]\n",
        "data2 = data2[['Sentence', 'Sentiment']]\n",
        "data3 = data3[['review', 'sentiment']]\n",
        "\n",
        "data1.columns = ['text', 'sentiment']\n",
        "data2.columns = ['text', 'sentiment']\n",
        "data3.columns = ['text', 'sentiment']\n",
        "\n",
        "# Convert the 'text' column to lowercase #\n",
        "\n",
        "data1.loc[:, 'text'] = data1['text'].str.lower()\n",
        "data2.loc[:, 'text'] = data2['text'].str.lower()\n",
        "data3.loc[:, 'text'] = data3['text'].str.lower()\n",
        "\n",
        "# Filter out rows where 'sentiment' is 'irrelevant' #\n",
        "\n",
        "data1 = data1[data1['sentiment'] != 'irrelevant']\n",
        "data2 = data2[data2['sentiment'] != 'irrelevant']\n",
        "data3 = data3[data3['sentiment'] != 'irrelevant']\n",
        "\n",
        "# Drop Nan values #\n",
        "\n",
        "data1.dropna(inplace=True)\n",
        "data2.dropna(inplace=True)\n",
        "data3.dropna(inplace=True)\n",
        "\n",
        "# If you don't have the runtime and computing power you should just use this #\n",
        "combined_data = data2\n",
        "\n",
        "# Uncomment these if you have proper runtime #\n",
        "# combined_data = pd.concat([data1, data2], ignore_index=True)\n",
        "# combined_data = pd.concat([combined_data, data3], ignore_index=True)\n",
        "\n",
        "# Vectorize text #\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(combined_data['text'])\n",
        "y = combined_data['sentiment']\n",
        "\n",
        "# Split data #\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train classifier #\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate on the combined test set #\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(\"Classification Report for Combined Dataset:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Calculate accuracy on the combined dataset #\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy for Combined Dataset: {accuracy:.4f}\")\n",
        "\n",
        "# Evaluate the classifier on individual datasets #\n",
        "\n",
        "# 1. Data1 Evaluation\n",
        "X_data1 = vectorizer.transform(data1['text'])\n",
        "y_data1 = data1['sentiment']\n",
        "y_data1_pred = classifier.predict(X_data1)\n",
        "accuracy_data1 = accuracy_score(y_data1, y_data1_pred)\n",
        "print(f\"Accuracy for Data1: {accuracy_data1:.4f}\")\n",
        "\n",
        "# 2. Data2 Evaluation\n",
        "X_data2 = vectorizer.transform(data2['text'])\n",
        "y_data2 = data2['sentiment']\n",
        "y_data2_pred = classifier.predict(X_data2)\n",
        "accuracy_data2 = accuracy_score(y_data2, y_data2_pred)\n",
        "print(f\"Accuracy for Data2: {accuracy_data2:.4f}\")\n",
        "\n",
        "# 3. Data3 Evaluation\n",
        "X_data3 = vectorizer.transform(data3['text'])\n",
        "y_data3 = data3['sentiment']\n",
        "y_data3_pred = classifier.predict(X_data3)\n",
        "accuracy_data3 = accuracy_score(y_data3, y_data3_pred)\n",
        "print(f\"Accuracy for Data3: {accuracy_data3:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwwxBWOMacfW",
        "outputId": "04901e87-d3b5-47af-8cd4-3043972d940f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Combined Dataset:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.47      0.35      0.40       175\n",
            "     neutral       0.74      0.84      0.79       622\n",
            "    positive       0.74      0.67      0.71       372\n",
            "\n",
            "    accuracy                           0.71      1169\n",
            "   macro avg       0.65      0.62      0.63      1169\n",
            "weighted avg       0.70      0.71      0.70      1169\n",
            "\n",
            "Accuracy for Combined Dataset: 0.7134\n",
            "Accuracy for Data1: 0.0000\n",
            "Accuracy for Data2: 0.8139\n",
            "Accuracy for Data3: 0.0362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chatgpt"
      ],
      "metadata": {
        "id": "siYlbucqbCAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28\n",
        "\n",
        "import openai\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Set your OpenAI API key #\n",
        "openai.api_key = \"API-KEY-HERE\"\n",
        "\n",
        "# Function to analyze sentiment using ChatGPT #\n",
        "def chatgpt_sentiment_analysis(text):\n",
        "    prompt = f\"Classify the sentiment of this text as Positive, Negative, or Neutral: '{text}'\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",  # You can also use \"gpt-4\"\n",
        "        messages=[{\"role\": \"system\", \"content\": \"You are a sentiment analysis assistant.\"},\n",
        "                  {\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=50\n",
        "    )\n",
        "\n",
        "    return response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "# Data Reading #\n",
        "\n",
        "data1 = pd.read_csv(\"/root/.cache/kagglehub/datasets/jp797498e/twitter-entity-sentiment-analysis/versions/2/twitter_training.csv\")\n",
        "data2 = pd.read_csv(\"/root/.cache/kagglehub/datasets/sbhatti/financial-sentiment-analysis/versions/4/data.csv\")\n",
        "data3 = pd.read_csv(\"/root/.cache/kagglehub/datasets/vishakhdapat/imdb-movie-reviews/versions/1/IMDB Dataset.csv\")\n",
        "\n",
        "# Data Prep #\n",
        "\n",
        "data1 = data1.iloc[:, [2, 3]]\n",
        "data2 = data2[['Sentence', 'Sentiment']]\n",
        "data3 = data3[['review', 'sentiment']]\n",
        "\n",
        "data1.columns = ['text', 'sentiment']\n",
        "data2.columns = ['text', 'sentiment']\n",
        "data3.columns = ['text', 'sentiment']\n",
        "\n",
        "# Convert the 'text' column to lowercase #\n",
        "\n",
        "data1.loc[:, 'text'] = data1['text'].str.lower()\n",
        "data2.loc[:, 'text'] = data2['text'].str.lower()\n",
        "data3.loc[:, 'text'] = data3['text'].str.lower()\n",
        "\n",
        "# Filter out rows where 'sentiment' is 'irrelevant' #\n",
        "\n",
        "data1 = data1[data1['sentiment'] != 'irrelevant']\n",
        "data2 = data2[data2['sentiment'] != 'irrelevant']\n",
        "data3 = data3[data3['sentiment'] != 'irrelevant']\n",
        "\n",
        "# Drop missing values #\n",
        "\n",
        "data1.dropna(inplace=True)\n",
        "data2.dropna(inplace=True)\n",
        "data3.dropna(inplace=True)\n",
        "\n",
        "# Function to classify sentiment using ChatGPT #\n",
        "def classify_sentiment_chatgpt(text):\n",
        "    sentiment = chatgpt_sentiment_analysis(text)\n",
        "    return sentiment\n",
        "\n",
        "# Function to calculate accuracy for a given dataset\n",
        "def calculate_accuracy(data):\n",
        "    predicted_sentiments = data['text'].apply(classify_sentiment_chatgpt)\n",
        "    accuracy = accuracy_score(data['sentiment'], predicted_sentiments)\n",
        "    return accuracy\n",
        "\n",
        "# Calculate accuracy for each dataset\n",
        "accuracy_data1 = calculate_accuracy(data1)\n",
        "accuracy_data2 = calculate_accuracy(data2)\n",
        "accuracy_data3 = calculate_accuracy(data3)\n",
        "\n",
        "# Print accuracy results\n",
        "print(f\"Accuracy for Data1: {accuracy_data1:.4f}\")\n",
        "print(f\"Accuracy for Data2: {accuracy_data2:.4f}\")\n",
        "print(f\"Accuracy for Data3: {accuracy_data3:.4f}\")"
      ],
      "metadata": {
        "id": "UC9-aEK2bCPa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}